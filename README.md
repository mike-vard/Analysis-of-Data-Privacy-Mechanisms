A short guide in data privacy mechanisms, and full analysis of Differential Privacy methods.

We live in the digital age, a time when more and more data is collected, stored and processed.
The question of analyzing large amounts of data, while preserving privacy, is one of the most up-to-date issues of the global social dialogue, employing a wide range of scientists.
In the course of history, many failed attempts have been made, indicating that the reasoning behind data privacy is full of traps. This has prompted increased interest in a mathematically robust definition of privacy.

This paper is concerned with ensuring privacy in personal data sets. Initially, we analyze modern generalization methods, compare their performance and emphasize their weaknesses, pointing that absolute disclosure prevention is impossible. Afterwards, we present the main method of randomization, Differential Privacy, which addresses all the currently known attacks, it has many practical implementations and knows many extensions that make it applicable to a wide range of situations.

In the last part of the thesis, we develop randomization algorithms of Differential Privacy in Python programming language and we analyze their performance.
